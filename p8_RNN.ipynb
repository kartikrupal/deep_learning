{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Lab Experiment-1",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kartikrupal/deep_learning/blob/main/p8_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-10-18T05:00:25.959315Z",
          "iopub.execute_input": "2023-10-18T05:00:25.961296Z",
          "iopub.status.idle": "2023-10-18T05:00:25.968825Z",
          "shell.execute_reply.started": "2023-10-18T05:00:25.961227Z",
          "shell.execute_reply": "2023-10-18T05:00:25.967606Z"
        },
        "trusted": true,
        "id": "wyY87jLx5FRj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example data (replace with your dataset)\n",
        "text_data = ['I love this movie', 'This is terrible', 'Neutral review','This is the worst','I Like You','He says Bad about you']\n",
        "labels = [2, 0,1,0,2,0]  # Labels (0 for negative, 1 for neutral, 2 for positive)\n",
        "\n",
        "# Tokenize and preprocess the text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text_data)\n",
        "sequences = tokenizer.texts_to_sequences(text_data)\n",
        "max_sequence_length = max([len(sequence) for sequence in sequences])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-18T05:04:46.926158Z",
          "iopub.execute_input": "2023-10-18T05:04:46.92664Z",
          "iopub.status.idle": "2023-10-18T05:04:46.934096Z",
          "shell.execute_reply.started": "2023-10-18T05:04:46.926609Z",
          "shell.execute_reply": "2023-10-18T05:04:46.93242Z"
        },
        "trusted": true,
        "id": "sioRUsDJ5FRn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "y = tf.keras.utils.to_categorical(labels)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-18T05:04:47.928765Z",
          "iopub.execute_input": "2023-10-18T05:04:47.929142Z",
          "iopub.status.idle": "2023-10-18T05:04:47.934997Z",
          "shell.execute_reply.started": "2023-10-18T05:04:47.929117Z",
          "shell.execute_reply": "2023-10-18T05:04:47.933909Z"
        },
        "trusted": true,
        "id": "xFQzwPEs5FRp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the RNN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=32, input_length=max_sequence_length))\n",
        "model.add(SimpleRNN(64))\n",
        "model.add(Dense(3, activation='softmax'))  # 3 output classes (positive, negative, neutral)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-18T05:04:48.912134Z",
          "iopub.execute_input": "2023-10-18T05:04:48.913473Z",
          "iopub.status.idle": "2023-10-18T05:04:49.009587Z",
          "shell.execute_reply.started": "2023-10-18T05:04:48.913416Z",
          "shell.execute_reply": "2023-10-18T05:04:49.008162Z"
        },
        "trusted": true,
        "id": "yWYVduy65FRr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=10, batch_size=16)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-18T05:06:03.06807Z",
          "iopub.execute_input": "2023-10-18T05:06:03.068562Z",
          "iopub.status.idle": "2023-10-18T05:06:04.537679Z",
          "shell.execute_reply.started": "2023-10-18T05:06:03.068528Z",
          "shell.execute_reply": "2023-10-18T05:06:04.536367Z"
        },
        "trusted": true,
        "id": "hgrr5Pht5FRt",
        "outputId": "7779e549-1705-4dce-df91-0dd718a4363e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.3333 - loss: 1.0962\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6667 - loss: 1.0594\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8333 - loss: 1.0233\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.8333 - loss: 0.9876\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 0.9519\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.9159\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.8796\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.8428\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.8055\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.7676\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b0f6041aa50>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare a test dataset\n",
        "test_data = ['I enjoyed the movie', 'This is the worst thing ever']\n",
        "test_labels = [2, 0]\n",
        "\n",
        "# Tokenize and preprocess the test data\n",
        "test_sequences = tokenizer.texts_to_sequences(test_data)\n",
        "X_test = pad_sequences(test_sequences, maxlen=max_sequence_length)\n",
        "y_test = tf.keras.utils.to_categorical(test_labels)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-18T05:06:06.060688Z",
          "iopub.execute_input": "2023-10-18T05:06:06.061159Z",
          "iopub.status.idle": "2023-10-18T05:06:06.068963Z",
          "shell.execute_reply.started": "2023-10-18T05:06:06.061127Z",
          "shell.execute_reply": "2023-10-18T05:06:06.067599Z"
        },
        "trusted": true,
        "id": "NriT3AZb5FRu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test dataset\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Loss: {loss}, Accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-18T05:06:07.168162Z",
          "iopub.execute_input": "2023-10-18T05:06:07.168598Z",
          "iopub.status.idle": "2023-10-18T05:06:07.509002Z",
          "shell.execute_reply.started": "2023-10-18T05:06:07.168559Z",
          "shell.execute_reply": "2023-10-18T05:06:07.507487Z"
        },
        "trusted": true,
        "id": "dXAVdL6q5FRw",
        "outputId": "6f3bf17a-5af7-4bf0-d10a-524f964b3f64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - accuracy: 1.0000 - loss: 0.7144\n",
            "Loss: 0.7144184708595276, Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on new text data\n",
        "new_text = [\"i hate this\",\"i love this\"]\n",
        "new_sequences = tokenizer.texts_to_sequences(new_text)\n",
        "X_new = pad_sequences(new_sequences, maxlen=max_sequence_length)\n",
        "predictions = model.predict(X_new)\n",
        "\n",
        "# Convert predictions to sentiment labels\n",
        "predicted_labels = [np.argmax(prediction) for prediction in predictions]\n",
        "print(\"Predicted Labels:\", predicted_labels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-18T05:06:40.100078Z",
          "iopub.execute_input": "2023-10-18T05:06:40.100554Z",
          "iopub.status.idle": "2023-10-18T05:06:40.183334Z",
          "shell.execute_reply.started": "2023-10-18T05:06:40.100517Z",
          "shell.execute_reply": "2023-10-18T05:06:40.181818Z"
        },
        "trusted": true,
        "id": "2V-3BRB75FRx",
        "outputId": "88356f10-b99b-4508-bc17-6a3b8e855496",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step\n",
            "Predicted Labels: [np.int64(1), np.int64(2)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
        "print(\"\\nPredictions:\")\n",
        "for text, pred in zip(new_text, predicted_labels):\n",
        "    print(f\"{text} → {label_map[pred]}\")"
      ],
      "metadata": {
        "id": "MRY2A_gI5FRz",
        "outputId": "cc074aaf-d0ea-47b3-d3b8-ac30668ad485",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predictions:\n",
            "i hate this → Neutral\n",
            "i love this → Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Expanded training data\n",
        "text_data = [\n",
        "    'I love this movie',\n",
        "    'This is terrible',\n",
        "    'Neutral review',\n",
        "    'This is the worst',\n",
        "    'I like you',\n",
        "    'He says bad things about you',\n",
        "    'I enjoyed the performance',\n",
        "    'The experience was awful',\n",
        "    'It’s okay, not great not bad',\n",
        "    'Absolutely fantastic movie!',\n",
        "    'Worst film ever made',\n",
        "    'Mediocre story but decent acting',\n",
        "    'Loved every part of it',\n",
        "    'Not good at all',\n",
        "    'Just average, nothing special',\n",
        "    'You are amazing',\n",
        "    'Disappointing ending',\n",
        "    'Could be better',\n",
        "    'Really liked the characters',\n",
        "    'Such a waste of time'\n",
        "]\n",
        "\n",
        "labels = [\n",
        "    2, 0, 1, 0, 2, 0, 2, 0, 1, 2,\n",
        "    0, 1, 2, 0, 1, 2, 0, 1, 2, 0\n",
        "]  # 0 = Negative, 1 = Neutral, 2 = Positive\n",
        "\n",
        "# Tokenize and convert text to sequences\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text_data)\n",
        "sequences = tokenizer.texts_to_sequences(text_data)\n",
        "max_sequence_length = max(len(seq) for seq in sequences)\n",
        "X = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "y = tf.keras.utils.to_categorical(labels, num_classes=3)\n",
        "\n",
        "# Build the RNN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=32))\n",
        "model.add(SimpleRNN(64))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=15, batch_size=4)\n",
        "\n",
        "# Expanded test data\n",
        "test_data = [\n",
        "    'I enjoyed the movie',\n",
        "    'This is the worst thing ever',\n",
        "    'Quite boring and slow',\n",
        "    'A masterpiece with brilliant direction',\n",
        "    'Nothing to say, very average',\n",
        "    'I really hated it',\n",
        "    'This was so good!',\n",
        "    'Fine but forgettable'\n",
        "]\n",
        "test_labels = [2, 0, 0, 2, 1, 0, 2, 1]\n",
        "\n",
        "# Tokenize and preprocess test data\n",
        "test_sequences = tokenizer.texts_to_sequences(test_data)\n",
        "X_test = pad_sequences(test_sequences, maxlen=max_sequence_length)\n",
        "y_test = tf.keras.utils.to_categorical(test_labels, num_classes=3)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Loss:\", loss, \"Accuracy:\", accuracy)\n",
        "\n",
        "# Make predictions on new unseen data\n",
        "new_text = [\"I like it\", \"It's not bad\", \"What a lovely surprise\", \"I hate the way it ended\"]\n",
        "new_sequences = tokenizer.texts_to_sequences(new_text)\n",
        "X_new = pad_sequences(new_sequences, maxlen=max_sequence_length)\n",
        "predictions = model.predict(X_new)\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "predicted_labels = [np.argmax(pred) for pred in predictions]\n",
        "print(\"Predicted Labels:\", predicted_labels)  # 0 = Negative, 1 = Neutral, 2 = Positive\n"
      ],
      "metadata": {
        "id": "38ufh-fKM7bj",
        "outputId": "0cde08c5-2e87-470e-8eae-9e2b88369872",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.2708 - loss: 1.0867\n",
            "Epoch 2/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4750 - loss: 1.0289  \n",
            "Epoch 3/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7222 - loss: 0.9703 \n",
            "Epoch 4/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8118 - loss: 0.9161 \n",
            "Epoch 5/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8285 - loss: 0.8452 \n",
            "Epoch 6/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8076 - loss: 0.7672 \n",
            "Epoch 7/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9382 - loss: 0.5989 \n",
            "Epoch 8/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9729 - loss: 0.4918 \n",
            "Epoch 9/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.4349 \n",
            "Epoch 10/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.3887 \n",
            "Epoch 11/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.2499 \n",
            "Epoch 12/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.1734 \n",
            "Epoch 13/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.1066 \n",
            "Epoch 14/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.1207 \n",
            "Epoch 15/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0713 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662ms/step - accuracy: 0.5000 - loss: 1.3379\n",
            "Loss: 1.3378734588623047 Accuracy: 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7b0ef02e6d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step\n",
            "Predicted Labels: [np.int64(2), np.int64(0), np.int64(0), np.int64(2)]\n"
          ]
        }
      ]
    }
  ]
}