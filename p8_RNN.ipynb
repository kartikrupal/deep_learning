{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Lab Experiment-1",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kartikrupal/deep_learning/blob/main/p8_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-10-18T05:00:25.959315Z",
          "iopub.execute_input": "2023-10-18T05:00:25.961296Z",
          "iopub.status.idle": "2023-10-18T05:00:25.968825Z",
          "shell.execute_reply.started": "2023-10-18T05:00:25.961227Z",
          "shell.execute_reply": "2023-10-18T05:00:25.967606Z"
        },
        "trusted": true,
        "id": "wyY87jLx5FRj"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example data (replace with your dataset)\n",
        "text_data = ['I love this movie', 'This is terrible', 'Neutral review','This is the worst','I Like You','He says Bad about you']\n",
        "labels = [2, 0,1,0,2,0]  # Labels (0 for negative, 1 for neutral, 2 for positive)\n",
        "\n",
        "# Tokenize and preprocess the text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text_data)\n",
        "sequences = tokenizer.texts_to_sequences(text_data)\n",
        "max_sequence_length = max([len(sequence) for sequence in sequences])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-18T05:04:46.926158Z",
          "iopub.execute_input": "2023-10-18T05:04:46.92664Z",
          "iopub.status.idle": "2023-10-18T05:04:46.934096Z",
          "shell.execute_reply.started": "2023-10-18T05:04:46.926609Z",
          "shell.execute_reply": "2023-10-18T05:04:46.93242Z"
        },
        "trusted": true,
        "id": "sioRUsDJ5FRn"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences"
      ],
      "metadata": {
        "id": "s-vkbTiJFZjQ",
        "outputId": "a23634e8-9c35-4462-f215-16b66b51dff6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 5, 1, 6],\n",
              " [1, 3, 7],\n",
              " [8, 9],\n",
              " [1, 3, 10, 11],\n",
              " [2, 12, 4],\n",
              " [13, 14, 15, 16, 4]]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "y = tf.keras.utils.to_categorical(labels)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-18T05:04:47.928765Z",
          "iopub.execute_input": "2023-10-18T05:04:47.929142Z",
          "iopub.status.idle": "2023-10-18T05:04:47.934997Z",
          "shell.execute_reply.started": "2023-10-18T05:04:47.929117Z",
          "shell.execute_reply": "2023-10-18T05:04:47.933909Z"
        },
        "trusted": true,
        "id": "xFQzwPEs5FRp"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the RNN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=32, input_length=max_sequence_length))\n",
        "model.add(SimpleRNN(64))\n",
        "model.add(Dense(3, activation='softmax'))  # 3 output classes (positive, negative, neutral)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-18T05:04:48.912134Z",
          "iopub.execute_input": "2023-10-18T05:04:48.913473Z",
          "iopub.status.idle": "2023-10-18T05:04:49.009587Z",
          "shell.execute_reply.started": "2023-10-18T05:04:48.913416Z",
          "shell.execute_reply": "2023-10-18T05:04:49.008162Z"
        },
        "trusted": true,
        "id": "yWYVduy65FRr",
        "outputId": "5d286842-4877-4178-da9a-d6e3c104f984",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=10, batch_size=16)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-18T05:06:03.06807Z",
          "iopub.execute_input": "2023-10-18T05:06:03.068562Z",
          "iopub.status.idle": "2023-10-18T05:06:04.537679Z",
          "shell.execute_reply.started": "2023-10-18T05:06:03.068528Z",
          "shell.execute_reply": "2023-10-18T05:06:04.536367Z"
        },
        "trusted": true,
        "id": "hgrr5Pht5FRt",
        "outputId": "3ff775a1-599f-4f7d-8264-85ac768f925e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.0000e+00 - loss: 1.1334\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669ms/step - accuracy: 0.3333 - loss: 1.1012\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.3333 - loss: 1.0704\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5000 - loss: 1.0406\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 1.0116\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6667 - loss: 0.9830\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6667 - loss: 0.9546\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.6667 - loss: 0.9262\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6667 - loss: 0.8978\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6667 - loss: 0.8692\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7cf738812a50>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare a test dataset\n",
        "test_data = ['I enjoyed the movie', 'This is the worst thing ever']\n",
        "test_labels = [2, 0]\n",
        "\n",
        "# Tokenize and preprocess the test data\n",
        "test_sequences = tokenizer.texts_to_sequences(test_data)\n",
        "X_test = pad_sequences(test_sequences, maxlen=max_sequence_length)\n",
        "y_test = tf.keras.utils.to_categorical(test_labels)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-18T05:06:06.060688Z",
          "iopub.execute_input": "2023-10-18T05:06:06.061159Z",
          "iopub.status.idle": "2023-10-18T05:06:06.068963Z",
          "shell.execute_reply.started": "2023-10-18T05:06:06.061127Z",
          "shell.execute_reply": "2023-10-18T05:06:06.067599Z"
        },
        "trusted": true,
        "id": "NriT3AZb5FRu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test dataset\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Loss: {loss}, Accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-18T05:06:07.168162Z",
          "iopub.execute_input": "2023-10-18T05:06:07.168598Z",
          "iopub.status.idle": "2023-10-18T05:06:07.509002Z",
          "shell.execute_reply.started": "2023-10-18T05:06:07.168559Z",
          "shell.execute_reply": "2023-10-18T05:06:07.507487Z"
        },
        "trusted": true,
        "id": "dXAVdL6q5FRw",
        "outputId": "e2fc599f-c92e-4c19-bb40-3ca2209c8406",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step - accuracy: 0.5000 - loss: 0.8331\n",
            "Loss: 0.8331120610237122, Accuracy: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on new text data\n",
        "new_text = [\"i hate this\",\"i love this\"]\n",
        "new_sequences = tokenizer.texts_to_sequences(new_text)\n",
        "X_new = pad_sequences(new_sequences, maxlen=max_sequence_length)\n",
        "predictions = model.predict(X_new)\n",
        "\n",
        "# Convert predictions to sentiment labels\n",
        "predicted_labels = [np.argmax(prediction) for prediction in predictions]\n",
        "print(\"Predicted Labels:\", predicted_labels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-18T05:06:40.100078Z",
          "iopub.execute_input": "2023-10-18T05:06:40.100554Z",
          "iopub.status.idle": "2023-10-18T05:06:40.183334Z",
          "shell.execute_reply.started": "2023-10-18T05:06:40.100517Z",
          "shell.execute_reply": "2023-10-18T05:06:40.181818Z"
        },
        "trusted": true,
        "id": "2V-3BRB75FRx",
        "outputId": "3a0c673b-f5c4-4d60-98bc-32eec62a5e17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Predicted Labels: [np.int64(2), np.int64(2)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
        "print(\"\\nPredictions:\")\n",
        "for text, pred in zip(new_text, predicted_labels):\n",
        "    print(f\"{text} → {label_map[pred]}\")"
      ],
      "metadata": {
        "id": "MRY2A_gI5FRz",
        "outputId": "aca79473-1e01-48fa-bb68-e6b7239f8ebd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predictions:\n",
            "i hate this → Positive\n",
            "i love this → Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Expanded training data\n",
        "text_data = [\n",
        "    'I love this movie',\n",
        "    'This is terrible',\n",
        "    'Neutral review',\n",
        "    'This is the worst',\n",
        "    'I like you',\n",
        "    'He says bad things about you',\n",
        "    'I enjoyed the performance',\n",
        "    'The experience was awful',\n",
        "    'It’s okay, not great not bad',\n",
        "    'Absolutely fantastic movie!',\n",
        "    'Worst film ever made',\n",
        "    'Mediocre story but decent acting',\n",
        "    'Loved every part of it',\n",
        "    'Not good at all',\n",
        "    'Just average, nothing special',\n",
        "    'You are amazing',\n",
        "    'Disappointing ending',\n",
        "    'Could be better',\n",
        "    'Really liked the characters',\n",
        "    'Such a waste of time'\n",
        "]\n",
        "\n",
        "labels = [\n",
        "    2, 0, 1, 0, 2, 0, 2, 0, 1, 2,\n",
        "    0, 1, 2, 0, 1, 2, 0, 1, 2, 0\n",
        "]  # 0 = Negative, 1 = Neutral, 2 = Positive\n",
        "\n",
        "# Tokenize and convert text to sequences\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text_data)\n",
        "sequences = tokenizer.texts_to_sequences(text_data)\n",
        "max_sequence_length = max(len(seq) for seq in sequences)\n",
        "X = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "y = tf.keras.utils.to_categorical(labels, num_classes=3)\n",
        "\n",
        "# Build the RNN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=32))\n",
        "model.add(SimpleRNN(64))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=15, batch_size=4)\n",
        "\n",
        "# Expanded test data\n",
        "test_data = [\n",
        "    'I enjoyed the movie',\n",
        "    'This is the worst thing ever',\n",
        "    'Quite boring and slow',\n",
        "    'A masterpiece with brilliant direction',\n",
        "    'Nothing to say, very average',\n",
        "    'I really hated it',\n",
        "    'This was so good!',\n",
        "    'Fine but forgettable'\n",
        "]\n",
        "test_labels = [2, 0, 0, 2, 1, 0, 2, 1]\n",
        "\n",
        "# Tokenize and preprocess test data\n",
        "test_sequences = tokenizer.texts_to_sequences(test_data)\n",
        "X_test = pad_sequences(test_sequences, maxlen=max_sequence_length)\n",
        "y_test = tf.keras.utils.to_categorical(test_labels, num_classes=3)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Loss:\", loss, \"Accuracy:\", accuracy)\n",
        "\n",
        "# Make predictions on new unseen data\n",
        "new_text = [\"I like it\", \"It's not bad\", \"What a lovely surprise\", \"I hate the way it ended\"]\n",
        "new_sequences = tokenizer.texts_to_sequences(new_text)\n",
        "X_new = pad_sequences(new_sequences, maxlen=max_sequence_length)\n",
        "predictions = model.predict(X_new)\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "predicted_labels = [np.argmax(pred) for pred in predictions]\n",
        "print(\"Predicted Labels:\", predicted_labels)  # 0 = Negative, 1 = Neutral, 2 = Positive\n"
      ],
      "metadata": {
        "id": "38ufh-fKM7bj",
        "outputId": "b4deb26a-99d7-48ec-fa65-611c6ba1a26e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4417 - loss: 1.0794\n",
            "Epoch 2/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8118 - loss: 1.0031 \n",
            "Epoch 3/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8528 - loss: 0.9672 \n",
            "Epoch 4/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9458 - loss: 0.8549 \n",
            "Epoch 5/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8799 - loss: 0.8186 \n",
            "Epoch 6/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9424 - loss: 0.6882 \n",
            "Epoch 7/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8694 - loss: 0.6468 \n",
            "Epoch 8/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9215 - loss: 0.5242 \n",
            "Epoch 9/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8347 - loss: 0.4543 \n",
            "Epoch 10/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9833 - loss: 0.2867 \n",
            "Epoch 11/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.2258 \n",
            "Epoch 12/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.1901 \n",
            "Epoch 13/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.1553 \n",
            "Epoch 14/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1290 \n",
            "Epoch 15/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0924 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step - accuracy: 0.5000 - loss: 1.3342\n",
            "Loss: 1.3342212438583374 Accuracy: 0.5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step\n",
            "Predicted Labels: [np.int64(2), np.int64(1), np.int64(0), np.int64(2)]\n"
          ]
        }
      ]
    }
  ]
}